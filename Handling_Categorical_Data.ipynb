{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handling Categorical Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVM6YSQo5F21jvUfiXs+mS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bluelord/ML_Cookbook/blob/main/Handling_Categorical_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvxh_XnT92lF"
      },
      "source": [
        "## Handling Categorical Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6Rf8TCS9z_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7951b5c5-27ee-4e3f-df5e-00f97069883d"
      },
      "source": [
        "# Encoding Nominal Categorical Features\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
        "\n",
        "# Create feature\n",
        "feature = np.array([[\"Texas\"],\n",
        "                    [\"California\"],\n",
        "                    [\"Texas\"],\n",
        "                    [\"Delaware\"],\n",
        "                    [\"Texas\"]])\n",
        "# Create one-hot encoder\n",
        "one_hot = LabelBinarizer()\n",
        "# One-hot encode feature\n",
        "one_hot.fit_transform(feature)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkXA-8BTNd9M",
        "outputId": "174a5b1f-0092-4563-ab41-c9d34f042e65"
      },
      "source": [
        "# View feature classes\n",
        "one_hot.classes_\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['California', 'Delaware', 'Texas'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4E9rUfiN1yS",
        "outputId": "49f3ac2b-3f79-4a50-dd55-e0e1184387b6"
      },
      "source": [
        "# If we want to reverse the one-hot encoding, we can use inverse_transform:\n",
        "# Reverse one-hot encoding\n",
        "one_hot.inverse_transform(one_hot.transform(feature))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Texas', 'California', 'Texas', 'Delaware', 'Texas'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "x6BOksCIN7Vi",
        "outputId": "faf512a1-f9df-4f7f-9075-8e1b3a9e9e20"
      },
      "source": [
        "# We can even use pandas to one-hot encode the feature:\n",
        "# Import library\n",
        "import pandas as pd\n",
        "# Create dummy variables from feature\n",
        "pd.get_dummies(feature[:,0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>California</th>\n",
              "      <th>Delaware</th>\n",
              "      <th>Texas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   California  Delaware  Texas\n",
              "0           0         0      1\n",
              "1           1         0      0\n",
              "2           0         0      1\n",
              "3           0         1      0\n",
              "4           0         0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH68OwOxOBlC",
        "outputId": "790ee9b5-1822-4275-c123-9eb00a9de61f"
      },
      "source": [
        "# One helpful ability of scikit-learn is to handle a situation\n",
        "# where each observation lists multiple classes:\n",
        "\n",
        "# Create multiclass feature\n",
        "multiclass_feature = [(\"Texas\", \"Florida\"),\n",
        "(\"California\", \"Alabama\"),\n",
        "(\"Texas\", \"Florida\"),\n",
        "(\"Delware\", \"Florida\"),\n",
        "(\"Texas\", \"Alabama\")]\n",
        "# Create multiclass one-hot encoder\n",
        "one_hot_multiclass = MultiLabelBinarizer()\n",
        "# One-hot encode multiclass feature\n",
        "one_hot_multiclass.fit_transform(multiclass_feature)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 1],\n",
              "       [1, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 1],\n",
              "       [0, 0, 1, 1, 0],\n",
              "       [1, 0, 0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaUKcWwXOVba"
      },
      "source": [
        "**Note:** Often recommended that after one-hot encoding a feature, we drop one of the one-hot encoded features in the resulting matrix to avoid linear dependence also known as Dummy Variable Trap."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnbof_2BOQiT",
        "outputId": "03d590ca-136d-47ba-98f4-2e5de71cfaae"
      },
      "source": [
        "# Encoding Ordinal Categorical Features\n",
        "\n",
        "# Create features\n",
        "dataframe = pd.DataFrame({\"Score\": [\"Low\", \"Low\", \"Medium\", \"Medium\", \"High\"]})\n",
        "# Create mapper\n",
        "scale_mapper = {\"Low\":1,\n",
        "\"Medium\":2,\n",
        "\"High\":3}\n",
        "# Replace feature values with scale\n",
        "dataframe[\"Score\"].replace(scale_mapper)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    2\n",
              "3    2\n",
              "4    3\n",
              "Name: Score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgQZV4JZRcAq"
      },
      "source": [
        "While transforming the ordinal classes into numerical values that maintain the notion of ordering. The most common approach is to create a dictionary that maps the string label of the class to a number and then apply that map to the feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZolTcgwOskj",
        "outputId": "bfffb116-abad-45dd-8bfe-979d44528e08"
      },
      "source": [
        "# Encoding Dictionaries of Features\n",
        "\n",
        "# Import library\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "# Create dictionary\n",
        "data_dict = [{\"Red\": 2, \"Blue\": 4}, \n",
        "             {\"Red\": 4, \"Blue\": 3},\n",
        "             {\"Red\": 1, \"Yellow\": 2},\n",
        "             {\"Red\": 2, \"Yellow\": 2}]\n",
        "# Create dictionary vectorizer\n",
        "dictvectorizer = DictVectorizer(sparse=False)\n",
        "# Convert dictionary to feature matrix\n",
        "features = dictvectorizer.fit_transform(data_dict)\n",
        "# View feature matrix\n",
        "features"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4., 2., 0.],\n",
              "       [3., 4., 0.],\n",
              "       [0., 1., 2.],\n",
              "       [0., 2., 2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n86iywJPSE6y"
      },
      "source": [
        "By default DictVectorizer outputs a sparse matrix that only stores elements with a value other than 0. This can be very helpful when we have massive matrices (often encountered in natural language processing) and want to minimize the memory requirements. We can force DictVectorizer to output a dense matrix using sparse=False."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdCyKkIYR9Ib",
        "outputId": "51f2fe3a-1045-47ff-9072-fff47e46ac37"
      },
      "source": [
        "# Get feature names\n",
        "feature_names = dictvectorizer.get_feature_names()\n",
        "# View feature names\n",
        "feature_names"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Blue', 'Red', 'Yellow']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3GkL2vRSLOS",
        "outputId": "cbd30f86-038e-481a-e3f7-115dc040fb34"
      },
      "source": [
        "# Imputing Missing Class Values\n",
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Create feature matrix with categorical feature\n",
        "X = np.array([[0, 2.10, 1.45],\n",
        "              [1, 1.18, 1.33],\n",
        "              [0, 1.22, 1.27], \n",
        "              [1, -0.21, -1.19]])\n",
        "# Create feature matrix with missing values in the categorical feature\n",
        "X_with_nan = np.array([[np.nan, 0.87, 1.31],\n",
        "[np.nan, -0.67, -0.22]])\n",
        "# Train KNN learner\n",
        "clf = KNeighborsClassifier(3, weights='distance')\n",
        "trained_model = clf.fit(X[:,1:], X[:,0])\n",
        "# Predict missing values' class\n",
        "imputed_values = trained_model.predict(X_with_nan[:,1:])\n",
        "# Join column of predicted class with their other features\n",
        "X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:,1:]))\n",
        "# Join two feature matrices\n",
        "np.vstack((X_with_imputed, X))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.  ,  0.87,  1.31],\n",
              "       [ 1.  , -0.67, -0.22],\n",
              "       [ 0.  ,  2.1 ,  1.45],\n",
              "       [ 1.  ,  1.18,  1.33],\n",
              "       [ 0.  ,  1.22,  1.27],\n",
              "       [ 1.  , -0.21, -1.19]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kegOQn0gSZxx",
        "outputId": "fa3bffb4-96b4-403e-ea2d-5c6eaf9a5bb1"
      },
      "source": [
        "# An alternative solution is to fill in missing values \n",
        "# with the feature’s most frequent value:\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imp_mean.fit([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]])\n",
        "\n",
        "SimpleImputer()\n",
        "X = [[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]]\n",
        "print(imp_mean.transform(X))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 7.   2.   3. ]\n",
            " [ 4.   3.5  6. ]\n",
            " [10.   3.5  9. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJCYpYU9TDmR"
      },
      "source": [
        "Handling Imbalanced Classes <br>\n",
        "Collect more data. If that isn’t possible, change the metrics used to evaluate your model. If that doesn’t work, consider using a model’s built-in class weight parameters (if available), downsampling, or upsampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDNf63xOSlNq",
        "outputId": "8bea18cb-8531-4f2d-fffe-7fb60b3d5bd2"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "# Load iris data\n",
        "iris = load_iris()\n",
        "# Create feature matrix\n",
        "features = iris.data\n",
        "# Create target vector\n",
        "target = iris.target\n",
        "# Remove first 40 observations\n",
        "features = features[40:,:]\n",
        "target = target[40:]\n",
        "# Create binary target vector indicating if class 0\n",
        "target = np.where((target == 0), 0, 1)\n",
        "# Look at the imbalanced target vector\n",
        "target"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QhcTOUCTQGq",
        "outputId": "925f1be8-881a-4a6c-f9b0-99c1a3072797"
      },
      "source": [
        "# Create weights\n",
        "weights = {0: .9, 1: 0.1}\n",
        "# Create random forest classifier with weights\n",
        "RandomForestClassifier(class_weight=weights)\n",
        "\n",
        "# Or you can pass balanced, which automatically \n",
        "# creates weights inversely proportional to class frequencies:\n",
        "# RandomForestClassifier(class_weight=\"balanced\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                       class_weight={0: 0.9, 1: 0.1}, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       max_samples=None, min_impurity_decrease=0.0,\n",
              "                       min_impurity_split=None, min_samples_leaf=1,\n",
              "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                       random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E5OLapMT04I"
      },
      "source": [
        "Alternatively, we can downsample the majority class or upsample the minority class. In downsampling, we randomly sample without replacement from the majority class. if the minority class has 10 observations, we\n",
        "will randomly select 10 observations from the majority class and use those 20 observations\n",
        "as our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cweu91uTwgf",
        "outputId": "526f463c-2250-489a-d48c-157447b3ce34"
      },
      "source": [
        "# Indicies of each class' observations\n",
        "i_class0 = np.where(target == 0)[0]\n",
        "i_class1 = np.where(target == 1)[0]\n",
        "# Number of observations in each class\n",
        "n_class0 = len(i_class0)\n",
        "n_class1 = len(i_class1)\n",
        "# For every observation of class 0, randomly sample\n",
        "# from class 1 without replacement\n",
        "i_class1_downsampled = np.random.choice(i_class1, size=n_class0, replace=False)\n",
        "# Join together class 0's target vector with the\n",
        "# downsampled class 1's target vector\n",
        "np.hstack((target[i_class0], target[i_class1_downsampled]))\n",
        "#array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTnxDTbVUP0X",
        "outputId": "a18a4ffc-cf28-43d7-c19f-cf3b979efbd6"
      },
      "source": [
        "# Join together class 0's feature matrix with the\n",
        "# downsampled class 1's feature matrix\n",
        "np.vstack((features[i_class0,:], features[i_class1_downsampled,:]))[0:5]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK9qc9wKUG_Z"
      },
      "source": [
        "Our other option is to upsample the minority class. In upsampling, for every observation in the majority class, we randomly select an observation from the minority class with replacement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgl7IHBZTymq",
        "outputId": "fccb444a-3e1c-4692-fbb2-3aab44164b57"
      },
      "source": [
        "# For every observation in class 1, randomly sample from class 0 with replacement\n",
        "i_class0_upsampled = np.random.choice(i_class0, size=n_class1, replace=True)\n",
        "# Join together class 0's upsampled target vector with class 1's target vector\n",
        "np.concatenate((target[i_class0_upsampled], target[i_class1]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buJ7rMJ8URo7",
        "outputId": "7be4febd-8bf9-4b79-cc3d-a4f9a26b09fb"
      },
      "source": [
        "# Join together class 0's upsampled feature matrix with class 1's feature matrix\n",
        "np.vstack((features[i_class0_upsampled,:], features[i_class1,:]))[0:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.8, 1.9, 0.4],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuj-Uv8iUq1J"
      },
      "source": [
        "second strategy is to use a model evaluation metric better suited to imbalanced\n",
        "classes. Accuracy is often used as a metric for evaluating the performance of a model, but when imbalanced classes are present accuracy can be ill suited. Some better metrics we discuss in later chapters are confusion matrices, precision, recall, F1 scores, and ROC curves."
      ]
    }
  ]
}